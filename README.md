å†™åœ¨å‰é¢/preface
========
ç›®å‰å·²ç»æœ‰è®¸å¤šæ¨èç³»ç»Ÿå¼€æºåº“ï¼Œä½†æ˜¯å®ç°çš„æ¨¡å‹å¤§å¤šæ¯”è¾ƒç»å…¸å’Œå¤è€ã€‚å› æ­¤æœ¬äººå†³å®šæŠŠä¸€äº›æ¯”è¾ƒæ–°çš„ï¼Œæœ‰ä»£è¡¨æ€§çš„å·¥ä½œè¿›è¡Œå¤ç°ï¼Œè®°å½•è‡ªå·±å­¦ä¹ çš„è¿‡ç¨‹å¹¶ä¸”åˆ†äº«ç»™å¤§å®¶ã€‚
å¦‚æœæœ‰ä¸è¶³ä¹‹å¤„éå¸¸å¸Œæœ›å¤§å®¶å¯ä»¥ç»™äºˆæŒ‡ç‚¹ã€‚

Currently, there are many open-source libraries for recommendation systems, but most of the implemented models are relatively classic and old. Therefore, I decided to reproduce some of the more recent and representative works, record my learning process and share it with everyone. If there are any shortcomings, I would really appreciate your guidance.

æ¨¡å‹åˆ—è¡¨/model list
========
1 å†·å¯åŠ¨/cold start

coming soon...

2 å¤šä»»åŠ¡å­¦ä¹ /multi-task models

ğŸ¤” ESMM: https://arxiv.org/pdf/1804.07931.pdf

ESMMæ¨¡å‹æ˜¯ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹æ³•ï¼Œç”¨äºé¢„æµ‹ç‚¹å‡»åçš„è½¬åŒ–ç‡ã€‚å®ƒåŒæ—¶å­¦ä¹ ä¸¤ä¸ªä»»åŠ¡ï¼šç‚¹å‡»ç‡å’Œç‚¹å‡»åè½¬åŒ–ç‡ï¼Œå¹¶åˆ©ç”¨å®ƒä»¬çš„ä¹˜ç§¯å…³ç³»æ¥éšå¼åœ°å­¦ä¹ è½¬åŒ–ç‡ï¼Œè§£å†³äº†æ ·æœ¬é€‰æ‹©åå·®å’Œæ•°æ®ç¨€ç–é—®é¢˜ã€‚

ESMM model is a multi-task learning method for predicting post-click conversion rate. It simultaneously learns two tasks: click-through rate and post-click conversion rate, and uses their product relationship to implicitly learn conversion rate, solving the problems of sample selection bias and data sparsity.

ğŸ¤” MoE: https://dl.acm.org/doi/pdf/10.1145/3219819.3220007

MoEæ˜¯ç”±Googleçš„ç ”ç©¶äººå‘˜æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹,æ¨¡å‹ç”±å¤šä¸ªä¸“å®¶ç½‘ç»œå’Œä¸€ä¸ªé—¨æ§å™¨ç»„æˆã€‚æœ€åï¼Œæ‰€æœ‰ä¸“å®¶çš„è¾“å‡ºè¢«åŠ æƒæ±‚å’Œï¼Œä»¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚

MoE is a multi-task learning model proposed by Google researchers. The model consists of multiple expert networks and one gate. Finally, the outputs of all experts are weighted and summed to generate the final output.

ğŸ¤” MMoE: https://dl.acm.org/doi/pdf/10.1145/3219819.3220007

MMoEæ˜¯ç”±Googleçš„ç ”ç©¶äººå‘˜æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹,æ¨¡å‹ç”±å¤šä¸ªä¸“å®¶ç½‘ç»œå’Œå¤šä¸ªé—¨æ§å™¨ç»„æˆã€‚æœ€åï¼Œæ‰€æœ‰ä¸“å®¶çš„è¾“å‡ºè¢«åŠ æƒæ±‚å’Œï¼Œä»¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚

MMoE is a multi-task learning model proposed by Google researchers. The model consists of multiple expert networks and several gates. Finally, the outputs of all experts are weighted and summed to generate the final output.

ğŸ¤” CGC: https://dl.acm.org/doi/pdf/10.1145/3383313.3412236

CGCæ˜¯è…¾è®¯æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¨¡å—ï¼Œæ—¨åœ¨è§£å†³è··è··æ¿é—®é¢˜ï¼ˆè´Ÿè¿ç§»é—®é¢˜ï¼‰ã€‚é€šè¿‡ä¸ºä¸åŒä»»åŠ¡å¼•å…¥ç‹¬ç«‹çš„ä¸“å®¶ç½‘ç»œè§£è€¦å­¦ä¹ ç›®æ ‡ã€‚

CGC is a multi-task learning module proposed by Tencent, aiming to solve the seesaw problem (negative transfer problem). It decouples the learning objectives by introducing independent expert networks for different tasks. 

ğŸ¤” PLE: https://dl.acm.org/doi/pdf/10.1145/3383313.3412236

PLEæ˜¯è…¾è®¯æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³è··è··æ¿é—®é¢˜ï¼ˆè´Ÿè¿ç§»é—®é¢˜ï¼‰ã€‚é€šè¿‡ä¸ºä¸åŒä»»åŠ¡å¼•å…¥ç‹¬ç«‹çš„ä¸“å®¶ç½‘ç»œè§£è€¦å­¦ä¹ ç›®æ ‡ã€‚å®ƒå¯ä»¥è¢«çœ‹åšæ˜¯å †å äº†å¤šå±‚CGCæ¨¡å—æ¸è¿›å¼åˆ†å±‚æŠ½å–å­¦ä¹ æ¨¡å‹ã€‚

PLE is a multi-task learning model proposed by Tencent, aiming to solve the seesaw problem (negative transfer problem). It decouples the learning objectives by introducing independent expert networks for different tasks. Moreover, it can be considered as a model stacking multiple CGC modules to progressively extract features.

ğŸ¤” Kuaishou-EBR: https://arxiv.org/pdf/2302.02657.pdf

å¿«æ‰‹åœ¨WWW2023æœ€æ–°æå‡ºçš„ç®—æ³•ã€‚æ–‡ç« ä»å¤šä»»åŠ¡å­¦ä¹ çš„è§’åº¦æå‡ºäº†embedding-basedæœç´¢å¬å›çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨åˆ†è€Œæ²»ä¹‹çš„æ€æƒ³æé«˜EBRå¬å›ç»“æœçš„å¤šæ ·æ€§ï¼Œæ–°é¢–æ€§ç­‰å¤šä¸ªç›®æ ‡ã€‚

The latest algorithm proposed by Kuaishou at WWW2023. The paper proposes an optimization scheme for embedding-based retrieval recall from the perspective of multi-task learning. The method uses the divide-and-conquer idea to improve the diversity, novelty and other objectives of EBR recall results.

ğŸ¤” AITM: https://arxiv.org/pdf/2105.08489.pdf

AITMæ˜¯ç¾å›¢å‘è¡¨åœ¨KDD2021çš„å¤šä»»åŠ¡å­¦ä¹ ç®—æ³•ã€‚æ–‡ç« æå‡ºå¤šä¸ªä»»åŠ¡ç›®æ ‡ä¹‹é—´æœ‰å…ˆåçš„è½¬åŒ–å…³ç³»ï¼ˆæ›å…‰-ç‚¹å‡»-åŠ è´­-ä»˜æ¬¾ï¼‰ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨è‡ªé€‚åº”ä¿¡æ¯ä¼ é€’æ¨¡å—æ¨¡æ‹Ÿå¤šæ­¥è½¬åŒ–è¿‡ç¨‹ä¸­çš„é¡ºåºä¾èµ–å…³ç³»ï¼Œå¯ä»¥æ ¹æ®ä¸åŒè½¬åŒ–é˜¶æ®µè‡ªé€‚åº”åœ°å­¦ä¹ è¦ä¼ é€’çš„ä¿¡æ¯å’Œä¼ é€’çš„ç¨‹åº¦ã€‚

AITM is a multi-task learning algorithm published by Meituan at KDD2021. The paper proposes that there is a sequential transformation relationship between multiple task objectives (exposure-click-add to cart-payment), and the model uses an adaptive information transformation module to simulate the sequential dependency relationship in the multi-step transformation process, which can adaptively learn the information and degree of transmission according to different stages.

3 åºåˆ—æ¨¡å‹/sequence models

â™¥ STAMP: 

coming soon...

â™¥ base model for DIN: https://arxiv.org/abs/1706.06978

DINçš„baseæ¨¡å‹ï¼Œå¯¹ç”¨æˆ·å†å²å…´è¶£å»ºæ¨¡é‡‡ç”¨äº†ç®€å•çš„æ±‚å’Œæ“ä½œï¼Œæ²¡æœ‰è€ƒè™‘å…´è¶£ä¹‹é—´çš„å…³ç³»ã€‚

DINâ€™s base model uses a simple summation operation to userâ€™s historical interests without the relationship between interests.

â™¥ DIN: https://arxiv.org/abs/1706.06978

DINæ¨¡å‹æ˜¯é˜¿é‡Œå¦ˆå¦ˆå›¢é˜Ÿæå‡ºçš„CTRé¢„ä¼°æ¨¡å‹ï¼Œå®ƒæ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ·±åº¦å…´è¶£ç½‘ç»œæ¨¡å‹ï¼Œç”¨äºå¯¹ç”¨æˆ·è¡Œä¸ºåºåˆ—æ•°æ®å»ºæ¨¡ã€‚DINæ¨¡å‹é€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†ç”¨æˆ·å†å²è¡Œä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªè¡Œä¸ºä¸å€™é€‰å¹¿å‘Šè¿›è¡Œäº¤äº’ï¼Œä»è€Œå­¦ä¹ åˆ°ç”¨æˆ·çš„å…´è¶£åå¥½ï¼Œå¹¶é¢„æµ‹ç”¨æˆ·æ˜¯å¦ä¼šç‚¹å‡»è¯¥å¹¿å‘Šã€‚

DIN (Deep Interest Network for Click-Through Rate Prediction) model is a CTR prediction model proposed by the Alibaba Mama team. It is a deep interest network model based on attention mechanism used to model user behavior sequence data. The DIN model interacts each behavior in the userâ€™s historical behavior sequence with the candidate advertisement by introducing attention mechanism, thus learning the userâ€™s interest preference and predicting whether the user will click the advertisement.

â™¥ DIEN: https://arxiv.org/pdf/1809.03672.pdf

â™¥ SIM: https://arxiv.org/pdf/2006.05639.pdf

SIMæ¨¡å‹æ˜¯ä¸€ç§åŸºäºæ£€ç´¢çš„CTRæ¨¡å‹ï¼Œç”±é˜¿é‡Œå¦ˆå¦ˆæå‡ºã€‚ä¼˜ç‚¹æ˜¯å¯ä»¥å¤„ç†é•¿åºåˆ—ç”¨æˆ·è¡Œä¸ºï¼ŒåŒæ—¶å…·æœ‰è¾ƒé«˜çš„é¢„æµ‹å‡†ç¡®ç‡å’Œè¾ƒä½çš„è®¡ç®—å¤æ‚åº¦ã€‚

SIM model is a retrieval-based CTR model proposed by Alibaba Mama team. Its advantage is that it can handle long sequence user behaviors while having high prediction accuracy and low computational complexity.

â™¥ TiCoSeRec: https://arxiv.org/pdf/2212.08262.pdf

TiCoSeRecæ˜¯åŸºäºCoSeRecç®—æ³•çš„ï¼Œç”±é˜¿é‡Œå·´å·´å’Œä¸œåŒ—å¤§å­¦æå‡ºã€‚æ–‡ç« æå‡ºäº†äº”ç§ä¸åŒçš„æ•°æ®å¢å¼ºç®—æ³•ï¼Œæå‡åºåˆ—æ¨¡å‹æ¨èæ•ˆæœã€‚å› æ­¤ï¼Œæœ¬ä»“åº“åªå®ç°æ•°æ®å¢å¼ºç®—æ³•è€Œä¸ç»™å‡ºå…·ä½“æ¨èç®—æ³•å®ç°ã€‚

TiCoSeRec, based on CoSeRec, is proposed by Alibaba and Northeast University. It presents five data argumentation algorithm to improve the performance of sequence recommender. Hence, here I just give the code of data argumentation instead of recommender.

æ–‡ä»¶ç»“æ„/document structure
========
MTL: å¤šä»»åŠ¡å­¦ä¹ æ–‡ä»¶å¤¹/multi-task

sequenceï¼šåºåˆ—æ¨èæ–‡ä»¶å¤¹/sequential recommender

coldï¼šå†·å¯åŠ¨æ–‡ä»¶å¤¹/cold start

å¿«é€Ÿå¼€å§‹/quick start
========
pending...

è‡´è°¢/acknowledgement
========
æ„Ÿè°¢æ‰€æœ‰å¯¹æ­¤é¡¹ç›®æœ‰è¿‡å¸®åŠ©çš„äººï¼ Thank you to everyone who has contributed to this project!

